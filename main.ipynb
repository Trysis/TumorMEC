{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Internal modules\n",
    "import os\n",
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "# External modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# User modules\n",
    "import src.utils.constantes as cst\n",
    "import src.utils.summary as summary\n",
    "import src.utils.auxiliary as auxiliary\n",
    "from src.processing import dataloader \n",
    "import src.models.scorer as scorer\n",
    "import src.models.models as models\n",
    "import src.models.display_results as display\n",
    "\n",
    "# Paths\n",
    "BASE_DIR = Path(\"./\")\n",
    "OUTPUT_DIR = BASE_DIR / \"results/\"\n",
    "DATA_DIR = BASE_DIR / \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataloader.Loader(\n",
    "    filepath=\"data/WTconcatenate.csv.gz\", sep=\",\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0          False\n",
       "1          False\n",
       "2          False\n",
       "3          False\n",
       "4          False\n",
       "           ...  \n",
       "2973698     True\n",
       "2973699     True\n",
       "2973700     True\n",
       "2973701     True\n",
       "2973702     True\n",
       "Name: Density20, Length: 2973703, dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.isnan(dataset.data[\"Density20\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conditions\n",
    "FILTER_COLUMNS = {\n",
    "    \"Condition\": \"WT\",\n",
    "    \"Type\": \"CD3\",\n",
    "    \"Mask\": 1,\n",
    "    \"Density20\": True,\n",
    "}\n",
    "# Filter dataset\n",
    "REMOVE_NONE = True\n",
    "REPLACE_ABERRANT = -1\n",
    "\n",
    "# Sample, feature, target columns\n",
    "SAMPLE = [\"FileName\"]\n",
    "REMOVE_SAMPLE = None\n",
    "FEATURES = {\"fiber-dist-shape\": cst.x_fiber_columns}\n",
    "TARGETS = [dataloader.enrich_2_cmask]\n",
    "TARGETS_COLNAMES = [target_col(return_key=True) for target_col in TARGETS]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training regimen\n",
    "CV = 8  # Number of CV-Folds\n",
    "LEAVE_ONE_OUT = False  # If True, CV is not used\n",
    "\n",
    "N_ITER = 50  # RandomSearch settings sampling number\n",
    "N_PROCESS = max(CV, 1)  # Multi-threading\n",
    "CV_TRAIN = True\n",
    "TRAIN = True\n",
    "SCORING = {\n",
    "    \"accuracy\": scorer.accuracy_score(to_scorer=True),\n",
    "    \"balanced_accuracy\": scorer.balanced_accuracy_score(to_scorer=True),\n",
    "    \"precision\": scorer.precision_score(to_scorer=True),\n",
    "    \"recall\": scorer.recall_score(to_scorer=True),\n",
    "    \"auc\": scorer.roc_auc_score(to_scorer=True),\n",
    "    \"mcc\": scorer.matthews_corrcoef(to_scorer=True),\n",
    "    \"f1\": scorer.f1_score(to_scorer=True),\n",
    "}\n",
    "SCORING_base = {\n",
    "    \"accuracy\": scorer.accuracy_score(to_scorer=False),\n",
    "    \"balanced_accuracy\": scorer.balanced_accuracy_score(to_scorer=False),\n",
    "    \"precision\": scorer.precision_score(to_scorer=False),\n",
    "    \"recall\": scorer.recall_score(to_scorer=False),\n",
    "    \"auc\": scorer.roc_auc_score(to_scorer=False),\n",
    "    \"mcc\": scorer.matthews_corrcoef(to_scorer=False),\n",
    "    \"f1\": scorer.f1_score(to_scorer=False),\n",
    "}\n",
    "FIT_WITH = \"f1\"\n",
    "TARGETS_WEIGHTS = \"balanced\"\n",
    "## Hyperparameters search\n",
    "hsearch_criterion = [\"entropy\",]\n",
    "hsearch_n_estimators = [16, 32, 64, 80]\n",
    "hsearch_max_features = [\"sqrt\"]\n",
    "hsearch_max_depths = [10, 15, 20]\n",
    "hsearch_min_s_split = [2, 4, 8]\n",
    "hsearch_min_s_leaf = [1, 5]\n",
    "hsearch_bootstrap = [True]\n",
    "hsearch_class_weight = [\"balanced\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importances attributes\n",
    "N_PERM = 30\n",
    "N_BORUTA = None\n",
    "\n",
    "## Process\n",
    "SAMPLE_GROUP = None if SAMPLE_GROUP == [] else SAMPLE_GROUP\n",
    "CV = 1 if LEAVE_ONE_OUT else CV\n",
    "N_ITER = 1 if not TRAIN_NEW_MODEL else N_ITER\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "loader = dataloader.DataLoader(\n",
    "    data_dir=DATA_DIR,\n",
    "    mask_condition=MASK_CONDITION,\n",
    "    mask_type=MASK_TYPE,\n",
    "    mask_tumor=MASK_TUMOR,\n",
    "    mask_fiber=MASK_DENSITY,\n",
    "    replace_aberrant=REPLACE_ABERRANT,\n",
    "    aberrant_columns=cst.aberrant_columns,\n",
    "    remove_none=REMOVE_NONE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe = loader.load_data(\n",
    "    targets=TARGETS,\n",
    "    type=cst.data_type,\n",
    "    save=False,\n",
    "    force_default=False,\n",
    "    remove_sample=REMOVE_SAMPLE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe.to_csv(\"WT.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "dataframe = loader.load_data(\n",
    "    targets=TARGETS,\n",
    "    type=cst.data_type,\n",
    "    save=False,\n",
    "    force_default=False,\n",
    "    remove_sample=REMOVE_SAMPLE,\n",
    ")\n",
    "\n",
    "filename = loader.filename_from_mask()\n",
    "rootname, ext = os.path.splitext(filename)\n",
    "rootname = \"LEAVE-ONE-OUT_\" + rootname if LEAVE_ONE_OUT else rootname\n",
    "rootname = \"UNGROUP_\" + rootname if SAMPLE_GROUP is None else rootname \n",
    "# Summary either for new model, or an already existant one\n",
    "summary_name = \"summary.txt\" if TRAIN_NEW_MODEL else \"summary_estimator.txt\"\n",
    "param_name = \"search_param.csv\" if TRAIN_NEW_MODEL else \"estimator_param.csv\"\n",
    "param_reduced_name = \"search_param-reduced_val.csv\" if TRAIN_NEW_MODEL else \"estimator_param_val.csv\"\n",
    "model_name = \"best_estimator.joblib\" if TRAIN_NEW_MODEL else \"estimator.joblib\"\n",
    "# Define X and Y\n",
    "for target_column in TARGETS_COLNAMES:\n",
    "    for key, features_column in FEATURES.items():\n",
    "        # Saving output\n",
    "        loader_name = f\"{rootname}_{key}_{target_column}\"  # MAIN DIR\n",
    "        loader_dir = auxiliary.create_dir(os.path.join(OUTPUT_DIR, loader_name), add_suffix=False)\n",
    "        # dir\n",
    "        cv_dir = auxiliary.create_dir(os.path.join(loader_dir, \"cv\"), add_suffix=False)\n",
    "        cv_plot_dir = auxiliary.create_dir(os.path.join(cv_dir, \"plots\"), add_suffix=False)\n",
    "        model_dir = auxiliary.create_dir(os.path.join(loader_dir, \"main\"), add_suffix=False)\n",
    "        train_test_dir = auxiliary.create_dir(os.path.join(loader_dir, \"train_test\"), add_suffix=False)\n",
    "        train_test_plot_dir = auxiliary.create_dir(os.path.join(train_test_dir, \"plots\"), add_suffix=False)\n",
    "        train_test_n_dir = auxiliary.create_dir(os.path.join(loader_dir, \"n_models\"), add_suffix=False)\n",
    "        train_test_n_plot_dir = auxiliary.create_dir(os.path.join(train_test_n_dir, \"plots\"), add_suffix=False)\n",
    "        train_test_n_i_dir = os.path.join(train_test_n_dir, \"model_{i}\")  # use with str.format\n",
    "        train_test_n_i_plot_dir = os.path.join(train_test_n_i_dir, \"plots\")  # use with str.format\n",
    "        # files\n",
    "        summary_file = os.path.join(loader_dir, summary_name)\n",
    "        hsearch_file = os.path.join(loader_dir, \"search_param.csv\")\n",
    "        hsearch_after_file = os.path.join(loader_dir, param_name)\n",
    "        hsearch_train_file = os.path.join(cv_dir, \"search_param-reduced_train.csv\")\n",
    "        hsearch_val_file = os.path.join(cv_dir, param_reduced_name)\n",
    "        model_file = os.path.join(model_dir, model_name)\n",
    "\n",
    "        cv_scores_train_file = os.path.join(cv_dir, \"cv_scores_train.csv\")\n",
    "        cv_scores_test_file = os.path.join(cv_dir, \"cv_scores_test.csv\")\n",
    "        cv_scores_train_plot_file = os.path.join(cv_plot_dir, \"cv_scores_train.png\")\n",
    "        cv_scores_val_plot_file = os.path.join(cv_plot_dir, \"cv_scores_val.png\")\n",
    "        cv_cfmatrix_train_file = os.path.join(cv_plot_dir, \"cv_cfmatrix_train.png\")\n",
    "        cv_cfmatrix_val_file = os.path.join(cv_plot_dir, \"cv_cfmatrix_val.png\")\n",
    "        \n",
    "        scores_train_file = os.path.join(train_test_dir, \"scores_train.csv\")\n",
    "        scores_test_file = os.path.join(train_test_dir, \"scores_test.csv\")\n",
    "        train_test_score_plot_file = os.path.join(train_test_plot_dir, \"train-test_score.png\")\n",
    "        cfmatrix_plot_train_file = os.path.join(train_test_plot_dir, \"cfmatrix_train.png\")\n",
    "        cfmatrix_plot_test_file = os.path.join(train_test_plot_dir, \"cfmatrix_test.png\")\n",
    "        \n",
    "        mdi_importance_file = os.path.join(train_test_dir, \"mean-decrease-impurity.csv\")\n",
    "        raw_permut_importance_train_file = os.path.join(train_test_dir, \"raw_permutation_train.csv\")\n",
    "        raw_permut_importance_test_file = os.path.join(train_test_dir, \"raw_permutation_test.csv\")\n",
    "        permut_importance_train_file = os.path.join(train_test_dir, \"permutation_train.csv\")\n",
    "        permut_importance_test_file = os.path.join(train_test_dir, \"permutation_test.csv\")\n",
    "        boruta_importance_train_file = os.path.join(train_test_dir, \"boruta_train.csv\")\n",
    "        boruta_importance_test_file = os.path.join(train_test_dir, \"boruta_test.csv\")\n",
    "        mdi_plot_file = os.path.join(train_test_plot_dir, \"mean-decrease-impurity.png\")\n",
    "        permut_plot_train_file = os.path.join(train_test_plot_dir, \"permutation_train.png\")\n",
    "        permut_plot_train_boxplot_file = os.path.join(train_test_plot_dir, \"permutation_boxplot_train.png\")\n",
    "        permut_plot_train_violin_file = os.path.join(train_test_plot_dir, \"permutation_violin_train.png\")\n",
    "        permut_plot_test_file = os.path.join(train_test_plot_dir, \"permutation_test.png\")\n",
    "        permut_plot_test_boxplot_file = os.path.join(train_test_plot_dir, \"permutation_boxplot_test.png\")\n",
    "        permut_plot_test_violin_file = os.path.join(train_test_plot_dir, \"permutation_violin_test.png\")\n",
    "        boruta_plot_train_file = os.path.join(train_test_plot_dir, \"boruta_train.png\")\n",
    "        boruta_plot_test_file = os.path.join(train_test_plot_dir, \"boruta_test.png\")\n",
    "        shap_plot_train_file = os.path.join(train_test_plot_dir, \"shap_train.png\")\n",
    "        shap_plot_test_file = os.path.join(train_test_plot_dir, \"shap_test.png\")\n",
    "        # For the N models (with N=Number of folds)\n",
    "        model_i_file = os.path.join(model_dir, \"estimator_{i}.joblib\")\n",
    "        n_scores_test_file = os.path.join(train_test_n_dir, \"n_scores_test.csv\")\n",
    "        mdi_i_importance_file = \"model_{i}_mean-decrease-impurity.csv\"  # to join\n",
    "        mdi_i_plot_file = \"model_{i}_mean-decrease-impurity.png\"\n",
    "        raw_i_permut_importance_train_file = \"model_{i}_raw_permutation_train.csv\"\n",
    "        raw_i_permut_importance_test_file = \"model_{i}_raw_permutation_test.csv\"\n",
    "        permut_i_importance_train_file = \"model_{i}_permutation_train.csv\"\n",
    "        permut_i_importance_test_file = \"model_{i}_permutation_test.csv\"\n",
    "        permut_i_plot_train_file = \"model_{i}_permutation_train.png\"\n",
    "        permut_i_plot_test_file = \"model_{i}_permutation_test.png\"\n",
    "        n_confusion_test_file = os.path.join(train_test_n_dir, \"n_confusion_test.csv\")\n",
    "        n_confusion_train_file = os.path.join(train_test_n_dir, \"n_confusion_train.csv\")\n",
    "        n_mdi_file = os.path.join(train_test_n_dir, \"n_mdi.csv\")\n",
    "        n_permut_train_file = os.path.join(train_test_n_dir, \"n_permutation_train.csv\")\n",
    "        n_permut_test_file = os.path.join(train_test_n_dir, \"n_permutation_test.csv\")\n",
    "        mean_cfmatrix_plot_train_file = os.path.join(train_test_n_plot_dir, \"cfmatrix_train.png\")\n",
    "        mean_cfmatrix_plot_test_file = os.path.join(train_test_n_plot_dir, \"cfmatrix_test.png\")\n",
    "\n",
    "        summary.summarize(\n",
    "            summary.mapped_summary({\n",
    "                \"Condition\": [c.name for c in MASK_CONDITION],\n",
    "                \"Type\": [t.name for t in MASK_TYPE],\n",
    "                \"Tumor\": [t.name for t in MASK_TUMOR],\n",
    "                \"Fiber\": [d.name for d in MASK_DENSITY],\n",
    "                \"Remove none\": REMOVE_NONE,\n",
    "                \"Replace aberrant\": REPLACE_ABERRANT,\n",
    "                \"NJOBS (Multi-threading)\": N_PROCESS,\n",
    "                \"SEED\": SEED,\n",
    "            }, map_sep=\":\"),\n",
    "            summary.arg_summary(\n",
    "                \"Importance parameters\",\n",
    "                \"\\n\" +\n",
    "                summary.mapped_summary({\n",
    "                    \"N-Permutation shuffle\": N_PERM,\n",
    "                    \"N-Boruta trials\": N_BORUTA,\n",
    "                }, map_sep=\"=\", padding_left=4),\n",
    "                new_line=False\n",
    "            ),\n",
    "            title=\"Parameters\",\n",
    "            filepath=summary_file, mode=\"w\"\n",
    "        )\n",
    "\n",
    "        summary.summarize(\n",
    "            summary.mapped_summary({\n",
    "                \"MODEL\": models.ESTIMATOR,\n",
    "                \"TEST RATIO\": TEST_SIZE,\n",
    "                \"GROUPS\": True if SAMPLE_GROUP else False,\n",
    "                \"Cross-validation N-Folds\": \"Leave one out\" if LEAVE_ONE_OUT else CV,\n",
    "                \"RandomSearch N-iter\": N_ITER,\n",
    "                \"Select best model with\": FIT_WITH\n",
    "            }, map_sep=\":\"),\n",
    "            summary.arg_summary(\n",
    "                \"Scoring\",\n",
    "                \"\\n\" + summary.mapped_summary(SCORING, padding_left=4),\n",
    "                new_line=False\n",
    "            ),\n",
    "            subtitle=\"Training regiment\",\n",
    "            filepath=summary_file\n",
    "        )\n",
    "        # Save search parameters for new model\n",
    "        if TRAIN_NEW_MODEL:\n",
    "            summary.arg_summary(\n",
    "                \"Hyperparameters search\",\n",
    "                \"\\n\" +\n",
    "                summary.mapped_summary({\n",
    "                    \"Criterion\": hsearch_criterion,\n",
    "                    \"N-Tree\": hsearch_n_estimators,\n",
    "                    \"N-Features\": hsearch_max_features,\n",
    "                    \"Max depths\": hsearch_max_depths,\n",
    "                    \"Min sample split\": hsearch_min_s_split,\n",
    "                    \"Min sample leaf\": hsearch_min_s_leaf,\n",
    "                    \"Bootstrap\": hsearch_bootstrap,\n",
    "                    \"Class-weight\": hsearch_class_weight\n",
    "                }, map_sep=\"=\", padding_left=4),\n",
    "                new_line=False, filepath=summary_file\n",
    "            )\n",
    "\n",
    "        # Features and Target(s)\n",
    "        x, y, groups = models.split_xy(\n",
    "            df=dataframe, x_columns=features_column, y_columns=target_column, groups=SAMPLE_GROUP\n",
    "        )\n",
    "        mapped_groups = None\n",
    "        if SAMPLE_GROUP:\n",
    "            label_groups = pd.DataFrame(dataframe[SAMPLE_GROUP].agg(';'.join, axis=1), columns=[\"label\"])\n",
    "            df_mapped_groups = label_groups.assign(groups=groups).drop_duplicates()    \n",
    "            mapped_groups = dict(zip(df_mapped_groups.label, df_mapped_groups.groups))\n",
    "\n",
    "        summary.df_summary(\n",
    "            x=x, y=y,\n",
    "            unique_groups=np.unique(groups),\n",
    "            x_columns=features_column,\n",
    "            y_columns=target_column,\n",
    "            groups_columns=SAMPLE_GROUP,\n",
    "            mapped_groups=mapped_groups,\n",
    "            new_line=True,\n",
    "            filepath=summary_file\n",
    "        )\n",
    "\n",
    "        # Train, Val, Test\n",
    "        x_train, x_test, y_train, y_test, groups_train, groups_test = models.split_data(\n",
    "            x, y, groups=groups, n_splits=1, test_size=TEST_SIZE, stratify=True, seed=SEED\n",
    "        )\n",
    "        u_groups_train = np.unique(groups_train) if groups_train is not None else None\n",
    "        u_groups_test = np.unique(groups_test) if groups_test is not None else None\n",
    "        if not LEAVE_ONE_OUT:\n",
    "            summary.summarize(\n",
    "                summary.xy_summary(\n",
    "                    x_train, y_train, unique_groups=u_groups_train, title=\"Train\",\n",
    "                    x_label=\"x_train shape\", y_label=\"y_train shape\", groups_label=\"groups_train\",\n",
    "                ),\n",
    "                summary.xy_summary(\n",
    "                    x_test, y_test, unique_groups=u_groups_test, title=\"Test\",\n",
    "                    x_label=\"x_test shape\", y_label=\"y_test shape\", groups_label=\"groups_test\",\n",
    "                ),\n",
    "                filepath=summary_file\n",
    "            )\n",
    "\n",
    "        # Kfold generator\n",
    "        cv_generator = models.cv_object(\n",
    "            n_split=CV, groups=groups_train, stratify=True, seed=SEED\n",
    "        )\n",
    "        # Model\n",
    "        estimator = None  # model trained on train\n",
    "        estimator_list = []  # models trained on train cv\n",
    "        estimator_param = dict()  # model parameters\n",
    "        # Score of model on each cv split\n",
    "        df_scores = None\n",
    "        idx_scores = None  # best model row index\n",
    "        # Hyperparameters search\n",
    "        if TRAIN_NEW_MODEL:\n",
    "            search = None\n",
    "            if not LEAVE_ONE_OUT:\n",
    "                # Default cross-validation\n",
    "                search = models.random_forest_search(\n",
    "                    x=x_train, y=y_train.ravel(), groups=groups_train,\n",
    "                    n_split=CV, stratify=True, seed=SEED, verbose=1,\n",
    "                    scoring=SCORING, n_iter=N_ITER, refit=FIT_WITH, n_jobs=N_PROCESS,\n",
    "                    class_weight=TARGETS_WEIGHTS, return_train_score=CV_TRAIN,\n",
    "                    cv_generator=cv_generator, random_state=SEED,\n",
    "                    param_criterion=hsearch_criterion,\n",
    "                    param_n_estimators=hsearch_n_estimators,\n",
    "                    param_max_features=hsearch_max_features,\n",
    "                    param_max_depths=hsearch_max_depths,\n",
    "                    param_min_s_split=hsearch_min_s_split,\n",
    "                    param_min_s_leaf=hsearch_min_s_leaf,\n",
    "                    param_bootstrap=hsearch_bootstrap,\n",
    "                    param_class_weight=hsearch_class_weight,\n",
    "                )\n",
    "            else:\n",
    "                # Leave one out (use all dataset)\n",
    "                search = models.random_forest_search(\n",
    "                    x=x, y=y.ravel(), groups=groups,\n",
    "                    n_split=CV, stratify=True, seed=SEED, verbose=1,\n",
    "                    scoring=SCORING, n_iter=N_ITER, refit=FIT_WITH, n_jobs=N_PROCESS,\n",
    "                    class_weight=TARGETS_WEIGHTS, return_train_score=CV_TRAIN,\n",
    "                    cv_generator=cv_generator, random_state=SEED,\n",
    "                    param_criterion=hsearch_criterion,\n",
    "                    param_n_estimators=hsearch_n_estimators,\n",
    "                    param_max_features=hsearch_max_features,\n",
    "                    param_max_depths=hsearch_max_depths,\n",
    "                    param_min_s_split=hsearch_min_s_split,\n",
    "                    param_min_s_leaf=hsearch_min_s_leaf,\n",
    "                    param_bootstrap=hsearch_bootstrap,\n",
    "                    param_class_weight=hsearch_class_weight,\n",
    "                )\n",
    "            # Model from searched parameters\n",
    "            estimator = search.best_estimator_\n",
    "            estimator_param = search.best_params_\n",
    "            # Save tested parameters\n",
    "            idx_scores = search.best_index_\n",
    "            df_search = pd.DataFrame(search.cv_results_)\n",
    "            df_search.to_csv(hsearch_file)\n",
    "            df_scores = df_search.iloc[idx_scores]\n",
    "        # Search for existing file parameters\n",
    "        else:\n",
    "            search_results = None\n",
    "            if auxiliary.isfile(hsearch_file):\n",
    "                search_results = pd.read_csv(hsearch_file)\n",
    "                search_param = search_results.loc[search_results[f\"rank_test_{FIT_WITH}\"] == 1][\"params\"]\n",
    "                estimator_param = eval(search_param.values[0])\n",
    "            elif isinstance(TRAIN_NEW_MODEL, str): # Search for other file ? or apply randomsearch ?\n",
    "                if auxiliary.isfile(TRAIN_NEW_MODEL):\n",
    "                    search_results = pd.read_csv(TRAIN_NEW_MODEL)\n",
    "            else:\n",
    "                raise Exception(\"Param File not found, change TRAIN_NEW_MODEL to False\")\n",
    "\n",
    "            # Model from already searched parameters\n",
    "            estimator = RandomForestClassifier(**estimator_param, random_state=SEED)\n",
    "            estimator.fit(x_train, y_train.ravel())\n",
    "            idx_scores = 0\n",
    "\n",
    "        # Save model\n",
    "        joblib.dump(estimator, model_file)\n",
    "        # List of model trained on each Train CV\n",
    "        dict_scores = dict()\n",
    "        for i, (train_index, val_index) in enumerate(cv_generator.split(x_train, y_train, groups_train)):\n",
    "            model_i = RandomForestClassifier(**estimator_param, random_state=SEED)\n",
    "            model_i.fit(x[train_index, :], y[train_index].ravel())\n",
    "            estimator_list.append(model_i)\n",
    "            # Save model {i}\n",
    "            joblib.dump(model_i, model_i_file.format(i=i))\n",
    "            if not TRAIN_NEW_MODEL:\n",
    "                dict_scores_i = models.scorer_model(\n",
    "                    model_i, x[val_index, :], y[val_index], SCORING_base,\n",
    "                    prefix=f\"split{i}_test_\"\n",
    "                )\n",
    "                dict_scores = {**dict_scores, **dict_scores_i}\n",
    "                if CV_TRAIN:\n",
    "                    dict_scores_i_train = models.scorer_model(\n",
    "                        model_i, x[train_index, :], y[train_index], SCORING_base,\n",
    "                        prefix=f\"split{i}_train_\"\n",
    "                    )\n",
    "                    dict_scores = {**dict_scores, **dict_scores_i_train}\n",
    "        \n",
    "        # N-Folds to summary\n",
    "        N_scores = -1\n",
    "        if SAMPLE_GROUP:\n",
    "            if LEAVE_ONE_OUT:\n",
    "                N_scores = len(mapped_groups)\n",
    "            else:\n",
    "                N_scores = CV\n",
    "        else:\n",
    "            if LEAVE_ONE_OUT:\n",
    "                N_scores = len(x)\n",
    "            else:\n",
    "                N_scores = CV\n",
    "\n",
    "        # Scores is None if search was not used\n",
    "        if df_scores is None:\n",
    "            df_scores = pd.DataFrame(dict_scores)\n",
    "            # Compute mean for each metric\n",
    "            for key in SCORING.keys():\n",
    "                split_scores_str = [f\"split{i}_test_{key}\" for i in range(N_scores)]\n",
    "                df_scores.loc[:, [f\"mean_test_{key}\"]] = df_scores[split_scores_str].mean(numeric_only=True, axis=1)\n",
    "                df_scores.loc[:, [f\"std_test_{key}\"]] = df_scores[split_scores_str].std(numeric_only=True, axis=1)\n",
    "                if CV_TRAIN:\n",
    "                    split_scores_train_str = [f\"split{i}_train_{key}\" for i in range(N_scores)]\n",
    "                    df_scores.loc[:, [f\"mean_train_{key}\"]] = df_scores[split_scores_train_str].mean(numeric_only=True, axis=1)\n",
    "                    df_scores.loc[:, [f\"std_train_{key}\"]] = df_scores[split_scores_train_str].std(numeric_only=True, axis=1)\n",
    "                df_scores.loc[:, [f\"rank_test_{key}\"]] = 1\n",
    "\n",
    "            # Save performances\n",
    "            df_scores.to_csv(hsearch_after_file)\n",
    "\n",
    "        summary.summarize(title=\"Results\", filepath=summary_file)\n",
    "        for i in range(N_scores):\n",
    "            split_scores_str = [f\"split{i}_test_{key}\" for key in SCORING.keys()]\n",
    "            result_i_scores = dict(zip(split_scores_str, df_scores[split_scores_str].values.ravel()))\n",
    "            summary.arg_summary(\n",
    "                f\"Split {i}\",\n",
    "                \"\\n\" +\n",
    "                summary.mapped_summary(\n",
    "                    result_i_scores,\n",
    "                    map_sep=\"=\", padding_left=4\n",
    "                ),\n",
    "                new_line=True,\n",
    "                filepath=summary_file\n",
    "            )\n",
    "\n",
    "        ## In clearer format\n",
    "        cv_val_scores = {\"model\": [], \"mean\": [], \"std\": [], \"rank\": [], \"score\": []}\n",
    "        cv_train_scores = {\"model\": [], \"mean\": [], \"std\": [], \"score\": []}\n",
    "        for idx, key in enumerate(SCORING.keys()):\n",
    "            key_score = [key] * N_ITER\n",
    "            key_model = [i for i in range(N_ITER)]\n",
    "            cv_val_scores[\"model\"].extend(key_model)\n",
    "            cv_val_scores[\"mean\"].extend(df_scores[f\"mean_test_{key}\"])\n",
    "            cv_val_scores[\"std\"].extend(df_scores[f\"std_test_{key}\"])\n",
    "            cv_val_scores[\"score\"].extend(key_score)\n",
    "            cv_val_scores[\"rank\"].extend(df_scores[f\"rank_test_{key}\"])\n",
    "            if CV_TRAIN:\n",
    "                cv_train_scores[\"model\"].extend(key_model)\n",
    "                cv_train_scores[\"mean\"].extend(df_scores[f\"mean_train_{key}\"])\n",
    "                cv_train_scores[\"std\"].extend(df_scores[f\"std_train_{key}\"])\n",
    "                cv_train_scores[\"score\"].extend(key_score)\n",
    "\n",
    "        df_cv_train_scores = None\n",
    "        df_cv_val_scores = pd.DataFrame(cv_val_scores)\n",
    "        df_cv_val_scores.to_csv(hsearch_val_file, index=False)\n",
    "        display.display_cv_scores(df_cv_val_scores, filepath=cv_scores_val_plot_file, title=\"CV performances\")\n",
    "        if CV_TRAIN:\n",
    "            df_cv_train_scores = pd.DataFrame(cv_train_scores)\n",
    "            df_cv_train_scores.to_csv(hsearch_train_file, index=False)\n",
    "            display.display_cv_scores(df_cv_train_scores, filepath=cv_scores_train_plot_file, title=\"CV performances\")\n",
    "\n",
    "        # CV - Confusion matrix\n",
    "        observed_cv_val, predicted_cv_val = models.predict_kmodel(\n",
    "            x=x_train, y=y_train, estimator=estimator,\n",
    "            kfolder=cv_generator.split(x_train, y_train.ravel(), groups_train),\n",
    "            return_train=False\n",
    "        )\n",
    "        display.display_confusion_matrix(\n",
    "            observed=observed_cv_val, predicted=predicted_cv_val,\n",
    "            labels=None, filepath=cv_cfmatrix_val_file\n",
    "        )\n",
    "        cv_perf_val, cv_perf_str_val = dict(), dict()\n",
    "        cv_perf_train, cv_perf_str_train = (dict(), dict()) if CV_TRAIN else (None, None)\n",
    "        for idx, key in enumerate(SCORING.keys()):  # TODO: Save a raw output of mean, std of best model in Train/Val\n",
    "            key_mean_val = df_scores[f'mean_test_{key}'].iloc[idx_scores]\n",
    "            key_std_val = df_scores[f'std_test_{key}'].iloc[idx_scores]\n",
    "            cv_perf_val[\"mean\"] = cv_perf_val.get(\"mean\", []) + [key_mean_val]\n",
    "            cv_perf_val[\"std\"] = cv_perf_val.get(\"std\", []) + [key_std_val]\n",
    "            cv_perf_val[\"score\"] = cv_perf_val.get(\"score\", []) + [key]\n",
    "            cv_perf_str_val[key] = \\\n",
    "                f\"mean={key_mean_val:.3f} \"u'\\u00b1'f\" {key_std_val:.3f}\"\n",
    "            if CV_TRAIN:\n",
    "                key_mean_train = df_scores[f'mean_train_{key}'].iloc[idx_scores]\n",
    "                key_std_train = df_scores[f'std_train_{key}'].iloc[idx_scores]\n",
    "                cv_perf_train[\"mean\"] = cv_perf_train.get(\"mean\", []) + [key_mean_train]\n",
    "                cv_perf_train[\"std\"] = cv_perf_train.get(\"std\", []) + [key_std_train]\n",
    "                cv_perf_train[\"score\"] = cv_perf_train.get(\"score\", []) + [key]\n",
    "                cv_perf_str_train[key] = \\\n",
    "                    f\"mean={key_mean_train:.3f} \"u'\\u00b1'f\" {key_std_train:.3f}\"\n",
    "\n",
    "        # Save raw cv scores\n",
    "        pd.DataFrame(cv_perf_val).to_csv(cv_scores_test_file, index=False)\n",
    "        if CV_TRAIN:\n",
    "            pd.DataFrame(cv_perf_train).to_csv(cv_scores_train_file, index=False)\n",
    "\n",
    "        parameters_str = \"Best parameters\" if TRAIN_NEW_MODEL else \"Parameters\"\n",
    "        summary.summarize(\n",
    "            summary.arg_summary(\n",
    "                parameters_str,\n",
    "                \"\\n\" +\n",
    "                summary.mapped_summary(\n",
    "                    estimator_param,\n",
    "                    map_sep=\"=\", padding_left=4\n",
    "                ),\n",
    "                new_line=False\n",
    "            ),\n",
    "            summary.arg_summary(\n",
    "                \"CV Val\", \"\\n\" + summary.mapped_summary(cv_perf_str_val, map_sep=\"=\", padding_left=4),\n",
    "                new_line=False\n",
    "            ),\n",
    "            filepath=summary_file\n",
    "        )\n",
    "        if CV_TRAIN:\n",
    "            summary.arg_summary(\n",
    "                \"CV Train\", \"\\n\" + summary.mapped_summary(cv_perf_str_train, map_sep=\"=\", padding_left=4),\n",
    "                filepath=summary_file\n",
    "            )\n",
    "\n",
    "        if not LEAVE_ONE_OUT:\n",
    "            # Train, Test - Score\n",
    "            ## Train\n",
    "            train_scores = models.scorer_model(\n",
    "                estimator=estimator,\n",
    "                x=x_train, y=y_train, scorer=SCORING_base\n",
    "            )\n",
    "\n",
    "            summary.arg_summary(\n",
    "                \"Train\", \"\\n\" + summary.mapped_summary(\n",
    "                    train_scores, map_sep=\"=\", padding_left=4\n",
    "                ), filepath=summary_file\n",
    "            )\n",
    "\n",
    "            df_train_scores = pd.DataFrame(train_scores).T\n",
    "            df_train_scores.to_csv(scores_train_file)\n",
    "            ## Test\n",
    "            test_scores = models.scorer_model(\n",
    "                estimator=estimator,\n",
    "                x=x_test, y=y_test, scorer=SCORING_base\n",
    "            )\n",
    "            summary.arg_summary(\n",
    "                \"Test\", \"\\n\" + summary.mapped_summary(\n",
    "                    test_scores, map_sep=\"=\", padding_left=4\n",
    "                ), filepath=summary_file\n",
    "            )\n",
    "            df_test_scores = pd.DataFrame(test_scores).T\n",
    "            df_test_scores.to_csv(scores_test_file)\n",
    "\n",
    "            # N models - Calculate score on test\n",
    "            n_test_scores_dict = dict()\n",
    "            for i, model_i in enumerate(estimator_list):\n",
    "                scores_test_i = models.scorer_model(\n",
    "                    estimator=model_i,\n",
    "                    x=x_test, y=y_test, scorer=SCORING_base,\n",
    "                    prefix=f\"model_{i}\"\n",
    "                )\n",
    "                n_test_scores_dict = {**n_test_scores_dict, **scores_test_i}\n",
    "            # Save to csv\n",
    "            pd.DataFrame(n_test_scores_dict).to_csv(n_scores_test_file)\n",
    "\n",
    "            # Train, Test - Score\n",
    "            display.display_train_test_scores(\n",
    "                train_scores=train_scores,\n",
    "                test_scores=test_scores,\n",
    "                title=\"Score\", filepath=train_test_score_plot_file\n",
    "            )\n",
    "            # Train, Test - Confusion matrix\n",
    "            if TRAIN:\n",
    "                observed_train, predicted_train = models.predict_model(x_train, y_train, estimator)\n",
    "                display.display_confusion_matrix(\n",
    "                    observed=observed_train, predicted=predicted_train, cmap=\"Reds\",\n",
    "                    labels=None, filepath=cfmatrix_plot_train_file, title=f\"train: {target_column}\"\n",
    "                )\n",
    "            observed_test, predicted_test = models.predict_model(x_test, y_test, estimator)\n",
    "            display.display_confusion_matrix(\n",
    "                observed=observed_test, predicted=predicted_test, cmap=\"Greens\",\n",
    "                labels=None, filepath=cfmatrix_plot_test_file, title=f\"test: {target_column}\"\n",
    "            )\n",
    "\n",
    "        # Feature Importance\n",
    "        ## Mean Decrease Impurity\n",
    "        df_mdi = pd.DataFrame(\n",
    "            models.forest_mdi_importance(rf_estimator=estimator, colnames=features_column)\n",
    "        )\n",
    "        df_mdi.to_csv(mdi_importance_file, index=False)\n",
    "        display.display_mdi_importance(mdi_importance=df_mdi, filepath=mdi_plot_file)\n",
    "\n",
    "        ## Permutation\n",
    "        ### Train\n",
    "        permutation_train = models.forest_permutation_importance(\n",
    "            estimator=estimator, x=x_train, y=y_train.ravel(),\n",
    "            scoring=SCORING[FIT_WITH], n_repeats=N_PERM,\n",
    "            colnames=features_column, n_jobs=N_PROCESS, seed=SEED\n",
    "        )\n",
    "        raw_permutation_train = pd.DataFrame(permutation_train.importances.T, columns=features_column)\n",
    "        df_permutation_train = pd.DataFrame({\n",
    "            \"importances_mean\": permutation_train[\"importances_mean\"],\n",
    "            \"importances_std\": permutation_train[\"importances_std\"],\n",
    "            \"colnames\": permutation_train[\"colnames\"]\n",
    "        })\n",
    "        raw_permutation_train.to_csv(raw_permut_importance_train_file, index=False)\n",
    "        df_permutation_train.to_csv(permut_importance_train_file, index=False)\n",
    "        display.display_permutation_importance(df_permutation_train, filepath=permut_plot_train_file)\n",
    "        display.display_raw_importance(raw_permutation_train, filepath=permut_plot_train_boxplot_file)\n",
    "        display.display_raw_importance(raw_permutation_train, violin=True, filepath=permut_plot_train_violin_file)\n",
    "        ### Test\n",
    "        permutation_test = models.forest_permutation_importance(\n",
    "            estimator=estimator, x=x_test, y=y_test.ravel(),\n",
    "            scoring=SCORING[FIT_WITH], n_repeats=N_PERM,\n",
    "            colnames=features_column,  n_jobs=N_PROCESS, seed=SEED\n",
    "        )\n",
    "        raw_permutation_test = pd.DataFrame(permutation_test.importances.T, columns=features_column)\n",
    "        df_permutation_test = pd.DataFrame({\n",
    "            \"importances_mean\": permutation_test[\"importances_mean\"],\n",
    "            \"importances_std\": permutation_test[\"importances_std\"],\n",
    "            \"colnames\": permutation_test[\"colnames\"]\n",
    "        })\n",
    "        raw_permutation_test.to_csv(raw_permut_importance_test_file, index=False)\n",
    "        df_permutation_test.to_csv(permut_importance_test_file, index=False)\n",
    "        display.display_permutation_importance(df_permutation_test, filepath=permut_plot_test_file)\n",
    "        display.display_raw_importance(raw_permutation_test, filepath=permut_plot_test_boxplot_file)\n",
    "        display.display_raw_importance(raw_permutation_test, violin=True, filepath=permut_plot_test_violin_file)\n",
    "\n",
    "        # Apply it with list of model\n",
    "        ## Confusion matrix\n",
    "        obs_pred_test_list = list()\n",
    "        confusion_test_dict = dict()\n",
    "        obs_pred_train_list = list()\n",
    "        confusion_train_dict = dict()\n",
    "        for i, model_i in enumerate(estimator_list):\n",
    "            observed_test, predicted_i_test = models.predict_model(x_test, y_test, model_i)\n",
    "            confusion_test_i = models.get_tn_fp_fn_tp(\n",
    "                observed_test, predicted_i_test,\n",
    "                prefix=f\"model_{i}\"\n",
    "            )\n",
    "            obs_pred_test_list.append([observed_test, predicted_i_test])\n",
    "            confusion_test_dict = {**confusion_test_dict, **confusion_test_i}\n",
    "            if TRAIN:\n",
    "                observed_train, predicted_i_train = models.predict_model(x_train, y_train, model_i)\n",
    "                confusion_train_i = models.get_tn_fp_fn_tp(\n",
    "                    observed_train, predicted_i_train,\n",
    "                    prefix=f\"model_{i}\"\n",
    "                )\n",
    "                obs_pred_train_list.append([observed_train, predicted_i_train])\n",
    "                confusion_train_dict = {**confusion_train_dict, **confusion_train_i}\n",
    "        # Save tn, fp, fn, tp\n",
    "        pd.DataFrame(confusion_test_dict).to_csv(n_confusion_test_file, index=False)\n",
    "        display.display_mean_confusion_matrix(\n",
    "            obs_pred_test_list, cmap=\"Greens\", labels=None,\n",
    "            filepath=mean_cfmatrix_plot_test_file, title=f\"mean test performance\"\n",
    "        )\n",
    "        if TRAIN:\n",
    "            pd.DataFrame(confusion_train_dict).to_csv(n_confusion_train_file, index=False)\n",
    "            display.display_mean_confusion_matrix(\n",
    "                obs_pred_train_list, cmap=\"Reds\", labels=None,\n",
    "                filepath=mean_cfmatrix_plot_train_file, title=f\"mean train performance\"\n",
    "            )\n",
    "\n",
    "        # Mean decrease accuracy\n",
    "        n_mdi = dict()\n",
    "        for i, model_i in enumerate(estimator_list):\n",
    "            model_i_dir = auxiliary.create_dir(train_test_n_i_dir.format(i=i), add_suffix=False)  # dir\n",
    "            model_i_plot_dir = auxiliary.create_dir(train_test_n_i_plot_dir.format(i=i), add_suffix=False)  # subdir\n",
    "            mdi_i = models.forest_mdi_importance(rf_estimator=model_i, colnames=features_column)\n",
    "            n_mdi = {  # save all results in one dict\n",
    "                **n_mdi,\n",
    "                f\"model_{i}_importances_mean\": mdi_i['importances_mean'],\n",
    "                f\"model_{i}_importances_std\": mdi_i[\"importances_std\"],\n",
    "            }\n",
    "            # Save output for model {i}\n",
    "            df_mdi_i = pd.DataFrame(mdi_i)\n",
    "            df_mdi_i.to_csv(os.path.join(model_i_dir, mdi_i_importance_file.format(i=i)), index=False)\n",
    "            display.display_mdi_importance(mdi_importance=df_mdi_i, filepath=os.path.join(model_i_plot_dir, mdi_i_plot_file.format(i=i)))\n",
    "        # Assign column names\n",
    "        n_mdi[\"colnames\"] = features_column\n",
    "        # Save concatenated mdi\n",
    "        pd.DataFrame(n_mdi).to_csv(n_mdi_file, index=False)\n",
    "\n",
    "        # Permutation\n",
    "        n_permut_test = dict()\n",
    "        n_permut_train = dict()\n",
    "        for i, model_i in enumerate(estimator_list):\n",
    "            model_i_dir = auxiliary.create_dir(train_test_n_i_dir.format(i=i), add_suffix=False)  # dir\n",
    "            model_i_plot_dir = auxiliary.create_dir(train_test_n_i_plot_dir.format(i=i), add_suffix=False)  # subdir\n",
    "            ## Train\n",
    "            permutation_train_i = models.forest_permutation_importance(\n",
    "                estimator=model_i, x=x_train, y=y_train.ravel(),\n",
    "                scoring=SCORING[FIT_WITH], n_repeats=N_PERM,\n",
    "                colnames=features_column,  n_jobs=N_PROCESS, seed=SEED\n",
    "            )\n",
    "            n_permut_train = {\n",
    "                **n_permut_train,\n",
    "                f\"model_{i}_importances_mean\": permutation_train_i[\"importances_mean\"],\n",
    "                f\"model_{i}_importances_std\": permutation_train_i[\"importances_std\"],\n",
    "            }\n",
    "            # Save output for model {i}\n",
    "            raw_permutation_i_train = pd.DataFrame(permutation_train_i.importances.T, columns=features_column)\n",
    "            df_permutation_i_train = pd.DataFrame({\n",
    "                \"importances_mean\": permutation_train_i[\"importances_mean\"],\n",
    "                \"importances_std\": permutation_train_i[\"importances_std\"],\n",
    "                \"colnames\": permutation_train_i[\"colnames\"]\n",
    "            })\n",
    "            df_permutation_i_train.to_csv(\n",
    "                os.path.join(model_i_dir, permut_i_importance_train_file.format(i=i)),\n",
    "                index=False\n",
    "            )\n",
    "            raw_permutation_i_train.to_csv(\n",
    "                os.path.join(model_i_dir, raw_i_permut_importance_train_file.format(i=i)),\n",
    "                index=False\n",
    "            )\n",
    "            display.display_permutation_importance(\n",
    "                df_permutation_i_train,\n",
    "                filepath=os.path.join(model_i_plot_dir, permut_i_plot_train_file.format(i=i)),\n",
    "            )\n",
    "            ## Test\n",
    "            permutation_test_i = models.forest_permutation_importance(\n",
    "                estimator=model_i, x=x_test, y=y_test.ravel(),\n",
    "                scoring=SCORING[FIT_WITH], n_repeats=N_PERM,\n",
    "                colnames=features_column,  n_jobs=N_PROCESS, seed=SEED\n",
    "            )\n",
    "            n_permut_test = {\n",
    "                **n_permut_test,\n",
    "                f\"model_{i}_importances_mean\": permutation_test_i[\"importances_mean\"],\n",
    "                f\"model_{i}_importances_std\": permutation_test_i[\"importances_std\"],\n",
    "            }\n",
    "            # Save output for model {i}\n",
    "            raw_permutation_i_test = pd.DataFrame(permutation_test_i.importances.T, columns=features_column)\n",
    "            df_permutation_i_test = pd.DataFrame({\n",
    "                \"importances_mean\": permutation_test_i[\"importances_mean\"],\n",
    "                \"importances_std\": permutation_test_i[\"importances_std\"],\n",
    "                \"colnames\": permutation_test_i[\"colnames\"]\n",
    "            })\n",
    "            df_permutation_i_test.to_csv(\n",
    "                os.path.join(model_i_dir, permut_i_importance_test_file.format(i=i)),\n",
    "                index=False\n",
    "            )\n",
    "            raw_permutation_i_test.to_csv(\n",
    "                os.path.join(model_i_dir, raw_i_permut_importance_test_file.format(i=i)),\n",
    "                index=False\n",
    "            )\n",
    "            display.display_permutation_importance(\n",
    "                df_permutation_i_test,\n",
    "                filepath=os.path.join(model_i_plot_dir, permut_i_plot_test_file.format(i=i))\n",
    "            )\n",
    "        # Assign column names\n",
    "        n_permut_train[\"colnames\"] = features_column\n",
    "        n_permut_test[\"colnames\"] = features_column\n",
    "        # Save to csv\n",
    "        pd.DataFrame(n_permut_train).to_csv(n_permut_train_file, index=False)\n",
    "        pd.DataFrame(n_permut_test).to_csv(n_permut_test_file, index=False)\n",
    "\n",
    "        ## Boruta\n",
    "        if N_BORUTA is not None:\n",
    "            ### Train\n",
    "            boruta_train = models.forest_boruta_importance(\n",
    "                estimator=estimator, x=x_train, y=y_train.ravel(),\n",
    "                colnames=features_column, n_trials=N_BORUTA\n",
    "            )\n",
    "            df_boruta_train = pd.DataFrame(boruta_train[\"feature_hit\"], index=[0])\n",
    "            df_boruta_train.to_csv(boruta_importance_train_file, index=False)\n",
    "            display.display_boruta_importance(\n",
    "                boruta_importance=boruta_train[\"feature_hit\"], treshold=boruta_train.treshold,\n",
    "                n_trials=boruta_train.n_trials, filepath=boruta_plot_train_file\n",
    "            )\n",
    "            ### Test\n",
    "            boruta_test = models.forest_boruta_importance(\n",
    "                estimator=estimator, x=x_test, y=y_test.ravel(),\n",
    "                colnames=features_column, n_trials=N_BORUTA\n",
    "            )\n",
    "            df_boruta_test = pd.DataFrame(boruta_test[\"feature_hit\"], index=[0])\n",
    "            df_boruta_test.to_csv(boruta_importance_test_file, index=False)\n",
    "            display.display_boruta_importance(\n",
    "                boruta_importance=boruta_test[\"feature_hit\"], treshold=boruta_test.treshold,\n",
    "                n_trials=boruta_test.n_trials, filepath=boruta_plot_test_file\n",
    "            )\n",
    "        \"\"\"\n",
    "        # Shap - Prediction explainer\n",
    "        ## Train\n",
    "        display.display_rf_summary_shap(\n",
    "            estimator=estimator,\n",
    "            feature_names=features_column,\n",
    "            x=x_train, filepath=shap_plot_train_file\n",
    "        )\n",
    "        ## Test\n",
    "        display.display_rf_summary_shap(\n",
    "            estimator=estimator,\n",
    "            feature_names=features_column,\n",
    "            x=x_test, filepath=shap_plot_test_file\n",
    "        )\n",
    "        \"\"\"\n",
    "        # TODO : PRC, Youden/Yudon index\n",
    "        # TODO : Confiance dans la prediction\n",
    "        # TODO : II. Predire WT & KI basé sur les fibres\n",
    "        # TODO : Predire Fibre à partir de T\n",
    "        # TODO : Analyses complémentaire, corrélation, projection\n",
    "        # TODO : Sauvegarder distribution des variables\n",
    "\n",
    "\"\"\"\n",
    "explain #shap \n",
    "https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Iris%20classification%20with%20scikit-learn.html\n",
    "https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/model_agnostic/Diabetes%20regression.html#Random-forest\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ecm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
